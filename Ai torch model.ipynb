{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Classification using PyTorch\n",
    "\n",
    "Garbage segregation involves separating wastes according to how it's handled or processed. It's important for recycling as some materials are recyclable and others are not.\n",
    "\n",
    "\n",
    "![Garbage Bins](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwebstockreview.net%2Fimages%2Fgarbage-clipart-wastebin-16.png&f=1&nofb=1)\n",
    "\n",
    "\n",
    "In this notebook we'll use PyTorch for classifying trash into various categories like metal, cardboard, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.135874Z",
     "start_time": "2024-03-11T17:24:14.170599Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-03-11T17:03:56.069041Z",
     "iopub.status.busy": "2024-03-11T17:03:56.067947Z",
     "iopub.status.idle": "2024-03-11T17:03:59.371734Z",
     "shell.execute_reply": "2024-03-11T17:03:59.370477Z",
     "shell.execute_reply.started": "2024-03-11T17:03:56.068980Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the classes present in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.139819Z",
     "start_time": "2024-03-11T17:24:15.137277Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:07.762141Z",
     "iopub.status.busy": "2024-03-11T17:04:07.760884Z",
     "iopub.status.idle": "2024-03-11T17:04:07.805048Z",
     "shell.execute_reply": "2024-03-11T17:04:07.803806Z",
     "shell.execute_reply.started": "2024-03-11T17:04:07.762087Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir  = 'Garbage classification/Garbage classification'\n",
    "\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply transformations to the dataset and import it for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.149681Z",
     "start_time": "2024-03-11T17:24:15.141384Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:07.807420Z",
     "iopub.status.busy": "2024-03-11T17:04:07.807037Z",
     "iopub.status.idle": "2024-03-11T17:04:09.975046Z",
     "shell.execute_reply": "2024-03-11T17:04:09.973747Z",
     "shell.execute_reply.started": "2024-03-11T17:04:07.807352Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transformations = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(data_dir, transform = transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function to see the image and its corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.362896Z",
     "start_time": "2024-03-11T17:24:15.151489Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:09.977739Z",
     "iopub.status.busy": "2024-03-11T17:04:09.977350Z",
     "iopub.status.idle": "2024-03-11T17:04:09.986981Z",
     "shell.execute_reply": "2024-03-11T17:04:09.985813Z",
     "shell.execute_reply.started": "2024-03-11T17:04:09.977685Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_sample(img, label):\n",
    "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.628247Z",
     "start_time": "2024-03-11T17:24:15.364270Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:09.989604Z",
     "iopub.status.busy": "2024-03-11T17:04:09.988856Z",
     "iopub.status.idle": "2024-03-11T17:04:10.473968Z",
     "shell.execute_reply": "2024-03-11T17:04:10.472839Z",
     "shell.execute_reply.started": "2024-03-11T17:04:09.989559Z"
    }
   },
   "outputs": [],
   "source": [
    "img, label = dataset[12]\n",
    "show_sample(img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Splitting Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.633768Z",
     "start_time": "2024-03-11T17:24:15.629717Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:10.477145Z",
     "iopub.status.busy": "2024-03-11T17:04:10.476787Z",
     "iopub.status.idle": "2024-03-11T17:04:10.486603Z",
     "shell.execute_reply": "2024-03-11T17:04:10.485453Z",
     "shell.execute_reply.started": "2024-03-11T17:04:10.477109Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the dataset into training, validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.638878Z",
     "start_time": "2024-03-11T17:24:15.635433Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:10.488898Z",
     "iopub.status.busy": "2024-03-11T17:04:10.488260Z",
     "iopub.status.idle": "2024-03-11T17:04:10.504218Z",
     "shell.execute_reply": "2024-03-11T17:04:10.502959Z",
     "shell.execute_reply.started": "2024-03-11T17:04:10.488843Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(dataset, [1593, 176, 758])\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.643025Z",
     "start_time": "2024-03-11T17:24:15.641018Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:11.353515Z",
     "iopub.status.busy": "2024-03-11T17:04:11.352347Z",
     "iopub.status.idle": "2024-03-11T17:04:11.358945Z",
     "shell.execute_reply": "2024-03-11T17:04:11.357445Z",
     "shell.execute_reply.started": "2024-03-11T17:04:11.353466Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create training and validation dataloaders using `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.646962Z",
     "start_time": "2024-03-11T17:24:15.644791Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:11.361879Z",
     "iopub.status.busy": "2024-03-11T17:04:11.361436Z",
     "iopub.status.idle": "2024-03-11T17:04:11.370841Z",
     "shell.execute_reply": "2024-03-11T17:04:11.369746Z",
     "shell.execute_reply.started": "2024-03-11T17:04:11.361834Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to visualize batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:15.651829Z",
     "start_time": "2024-03-11T17:24:15.648473Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:11.395992Z",
     "iopub.status.busy": "2024-03-11T17:04:11.395047Z",
     "iopub.status.idle": "2024-03-11T17:04:11.403749Z",
     "shell.execute_reply": "2024-03-11T17:04:11.402330Z",
     "shell.execute_reply.started": "2024-03-11T17:04:11.395944Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:17.762084Z",
     "start_time": "2024-03-11T17:24:15.653851Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:11.406479Z",
     "iopub.status.busy": "2024-03-11T17:04:11.406076Z",
     "iopub.status.idle": "2024-03-11T17:04:16.581864Z",
     "shell.execute_reply": "2024-03-11T17:04:16.580451Z",
     "shell.execute_reply.started": "2024-03-11T17:04:11.406429Z"
    }
   },
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Base:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:17.771124Z",
     "start_time": "2024-03-11T17:24:17.764940Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:16.585753Z",
     "iopub.status.busy": "2024-03-11T17:04:16.584868Z",
     "iopub.status.idle": "2024-03-11T17:04:16.601937Z",
     "shell.execute_reply": "2024-03-11T17:04:16.600642Z",
     "shell.execute_reply.started": "2024-03-11T17:04:16.585698Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using ResNet50 for classifying images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.162796Z",
     "start_time": "2024-03-11T17:24:17.773383Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:16.603606Z",
     "iopub.status.busy": "2024-03-11T17:04:16.603203Z",
     "iopub.status.idle": "2024-03-11T17:04:18.150088Z",
     "shell.execute_reply": "2024-03-11T17:04:18.148784Z",
     "shell.execute_reply.started": "2024-03-11T17:04:16.603572Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()  # Ensure the model is in evaluation mode after loading weights\n",
    "    return model\n",
    "\n",
    "# Instantiate your model\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting to GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs tend to perform faster calculations than CPU. Let's take this advantage and use GPU for computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.170502Z",
     "start_time": "2024-03-11T17:24:18.164788Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.153544Z",
     "iopub.status.busy": "2024-03-11T17:04:18.153151Z",
     "iopub.status.idle": "2024-03-11T17:04:18.166070Z",
     "shell.execute_reply": "2024-03-11T17:04:18.164736Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.153506Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.175326Z",
     "start_time": "2024-03-11T17:24:18.173514Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.167668Z",
     "iopub.status.busy": "2024-03-11T17:04:18.167297Z",
     "iopub.status.idle": "2024-03-11T17:04:18.194235Z",
     "shell.execute_reply": "2024-03-11T17:04:18.193016Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.167633Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = get_default_device()\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.179631Z",
     "start_time": "2024-03-11T17:24:18.177908Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.196072Z",
     "iopub.status.busy": "2024-03-11T17:04:18.195646Z",
     "iopub.status.idle": "2024-03-11T17:04:18.246976Z",
     "shell.execute_reply": "2024-03-11T17:04:18.245568Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.196023Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dl = DeviceDataLoader(train_dl, device)\n",
    "# val_dl = DeviceDataLoader(val_dl, device)\n",
    "# to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function for fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.185807Z",
     "start_time": "2024-03-11T17:24:18.181625Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.248961Z",
     "iopub.status.busy": "2024-03-11T17:04:18.248611Z",
     "iopub.status.idle": "2024-03-11T17:04:18.260313Z",
     "shell.execute_reply": "2024-03-11T17:04:18.259115Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.248926Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.190859Z",
     "start_time": "2024-03-11T17:24:18.188949Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.262282Z",
     "iopub.status.busy": "2024-03-11T17:04:18.261945Z",
     "iopub.status.idle": "2024-03-11T17:04:18.846642Z",
     "shell.execute_reply": "2024-03-11T17:04:18.845613Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.262249Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = to_device(ResNet(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.195750Z",
     "start_time": "2024-03-11T17:24:18.193021Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:18.848231Z",
     "iopub.status.busy": "2024-03-11T17:04:18.847916Z",
     "iopub.status.idle": "2024-03-11T17:04:25.073627Z",
     "shell.execute_reply": "2024-03-11T17:04:25.072145Z",
     "shell.execute_reply.started": "2024-03-11T17:04:18.848200Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.198879Z",
     "start_time": "2024-03-11T17:24:18.197155Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:04:25.077429Z",
     "iopub.status.busy": "2024-03-11T17:04:25.077040Z",
     "iopub.status.idle": "2024-03-11T17:06:09.524170Z",
     "shell.execute_reply": "2024-03-11T17:06:09.522717Z",
     "shell.execute_reply.started": "2024-03-11T17:04:25.077375Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_epochs = 8\n",
    "# opt_func = torch.optim.Adam\n",
    "# lr = 5.5e-5\n",
    "\n",
    "# history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n",
    "# save_model(model, 'resnet_model_weights.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.203258Z",
     "start_time": "2024-03-11T17:24:18.200871Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:06:21.173011Z",
     "iopub.status.busy": "2024-03-11T17:06:21.171739Z",
     "iopub.status.idle": "2024-03-11T17:06:21.467038Z",
     "shell.execute_reply": "2024-03-11T17:06:21.465833Z",
     "shell.execute_reply.started": "2024-03-11T17:06:21.172956Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_accuracies(history):\n",
    "#     accuracies = [x['val_acc'] for x in history]\n",
    "#     plt.plot(accuracies, '-x')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.title('Accuracy vs. No. of epochs');\n",
    "\n",
    "# plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.207953Z",
     "start_time": "2024-03-11T17:24:18.205558Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:06:23.453382Z",
     "iopub.status.busy": "2024-03-11T17:06:23.452349Z",
     "iopub.status.idle": "2024-03-11T17:06:23.757567Z",
     "shell.execute_reply": "2024-03-11T17:06:23.756092Z",
     "shell.execute_reply.started": "2024-03-11T17:06:23.453326Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_losses(history):\n",
    "#     train_losses = [x.get('train_loss') for x in history]\n",
    "#     val_losses = [x['val_loss'] for x in history]\n",
    "#     plt.plot(train_losses, '-bx')\n",
    "#     plt.plot(val_losses, '-rx')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.legend(['Training', 'Validation'])\n",
    "#     plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "# plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:24:18.691544Z",
     "start_time": "2024-03-11T17:24:18.211937Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:07:02.806370Z",
     "iopub.status.busy": "2024-03-11T17:07:02.805465Z",
     "iopub.status.idle": "2024-03-11T17:07:02.813225Z",
     "shell.execute_reply": "2024-03-11T17:07:02.811847Z",
     "shell.execute_reply.started": "2024-03-11T17:07:02.806314Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model, model_filepath):\n",
    "    # Load the model if it's not already loaded\n",
    "    if not hasattr(predict_image, 'model_loaded'):\n",
    "        # Instantiate a new model with the same architecture\n",
    "        predict_image.model_loaded = ResNet()\n",
    "        # Load the saved model weights\n",
    "        predict_image.model_loaded = load_model(predict_image.model_loaded, model_filepath)\n",
    "\n",
    "    # Ensure consistency between the model device and the input tensor device\n",
    "    device = next(predict_image.model_loaded.parameters()).device\n",
    "    # Move the input tensor to the same device as the model\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    prob, preds = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return dataset.classes[preds[0].item()]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have trained your model and saved its weights\n",
    "model_filepath = 'resnet_model_weights.pth'  # Provide the correct filepath\n",
    "predicted_class = predict_image(img, model, model_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the model's predictions on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:32:41.775811Z",
     "start_time": "2024-03-11T17:32:41.402411Z"
    }
   },
   "outputs": [],
   "source": [
    "model_loaded = ResNet()\n",
    "model= load_model(model_loaded, 'resnet_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:36:03.016505Z",
     "start_time": "2024-03-11T17:36:02.617710Z"
    },
    "execution": {
     "iopub.execute_input": "2024-03-11T17:07:34.382409Z",
     "iopub.status.busy": "2024-03-11T17:07:34.381440Z",
     "iopub.status.idle": "2024-03-11T17:07:34.793479Z",
     "shell.execute_reply": "2024-03-11T17:07:34.792261Z",
     "shell.execute_reply.started": "2024-03-11T17:07:34.382340Z"
    }
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[17]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model, model_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:36:00.273149Z",
     "start_time": "2024-03-11T17:35:59.883123Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_external_image(image_name):\n",
    "    image = Image.open(Path('./' + image_name))\n",
    "\n",
    "    example_image = transformations(image)\n",
    "    plt.imshow(example_image.permute(1, 2, 0))\n",
    "    print(\"The image resembles\", predict_image(example_image, model, model_filepath) + \".\")\n",
    "    \n",
    "predict_external_image('WhatsApp Image 2024-03-08 at 11.07.38 PM.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:32:51.699628Z",
     "start_time": "2024-03-11T17:32:51.694743Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image\n",
    "# from pathlib import Path\n",
    "\n",
    "# def predict_external_image(model, model_filepath):\n",
    "#     # Open camera\n",
    "#     cap = cv2.VideoCapture(1)\n",
    "#     if not cap.isOpened():\n",
    "#         print(\"Error: Could not open camera.\")\n",
    "#         return\n",
    "    \n",
    "#     while True:\n",
    "#         # Capture frame-by-frame\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Error: Could not read frame.\")\n",
    "#             break\n",
    "        \n",
    "#         # Convert frame to PIL Image\n",
    "#         image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "#         # Display the captured image\n",
    "#         plt.imshow(image)\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Perform prediction\n",
    "#         example_image = transformations(image)\n",
    "#         predicted_class = predict_image(example_image, model, model_filepath)\n",
    "#         print(\"Predicted class:\", predicted_class)\n",
    "        \n",
    "#         # Check for user input to exit\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    \n",
    "#     # Release the camera\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming you have already trained your model and saved its weights\n",
    "# model_filepath = 'resnet_model_weights.pth'  # Provide the correct filepath\n",
    "# predict_external_image(model, model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:32:53.918754Z",
     "start_time": "2024-03-11T17:32:53.912311Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import tkinter as tk\n",
    "# from PIL import Image, ImageTk\n",
    "# from pathlib import Path\n",
    "# import time\n",
    "\n",
    "# def capture_image():\n",
    "#     global cap, model, model_filepath\n",
    "    \n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "#         example_image = transformations(image)\n",
    "#         predicted_class = predict_image(example_image, model, model_filepath)\n",
    "        \n",
    "#         label.config(text=\"Predicted class: \" + predicted_class)\n",
    "#         canvas.image = ImageTk.PhotoImage(image=image)\n",
    "#         canvas.create_image(0, 0, anchor=tk.NW, image=canvas.image)\n",
    "\n",
    "#     root.after(20000, capture_image)  # Capture image every 20 seconds\n",
    "\n",
    "# root = tk.Tk()\n",
    "# root.title(\"Image Capture\")\n",
    "\n",
    "# canvas = tk.Canvas(root, width=640, height=480)\n",
    "# canvas.pack()\n",
    "\n",
    "# label = tk.Label(root, text=\"\")\n",
    "# label.pack()\n",
    "\n",
    "# # Open camera\n",
    "# cap = cv2.VideoCapture(1)\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error: Could not open camera.\")\n",
    "#     root.destroy()\n",
    "# else:\n",
    "#     model_filepath = 'resnet_model_weights.pth'  # Provide the correct filepath\n",
    "#     capture_image()\n",
    "\n",
    "# root.mainloop()\n",
    "\n",
    "# # Release the camera\n",
    "# if cap.isOpened():\n",
    "#     cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:38:40.876823Z",
     "start_time": "2024-03-11T17:36:17.396359Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PySimpleGUI as sg\n",
    "from PIL import Image, ImageTk\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_external_image(model, model_filepath):\n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Convert frame to PIL Image\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Display the captured image\n",
    "        window['image'].update(data=cv2.imencode('.png', frame)[1].tobytes())\n",
    "        \n",
    "        # Perform prediction\n",
    "        example_image = transformations(image)\n",
    "        predicted_class = predict_image(example_image, model, model_filepath)\n",
    "        window['output'].update(\"Predicted class: \" + predicted_class)\n",
    "        \n",
    "        # Check for user input to exit\n",
    "        event, values = window.read(timeout=20)  # Timeout for event polling set to 20ms\n",
    "        if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "            break\n",
    "    \n",
    "    # Release the camera\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Create the PySimpleGUI layout\n",
    "layout = [\n",
    "    [sg.Image(filename='', key='image')],\n",
    "    [sg.Text(size=(40, 1), key='output')],\n",
    "    [sg.Button('Exit')]\n",
    "]\n",
    "\n",
    "# Create the window\n",
    "window = sg.Window('Image Capture', layout, finalize=True)\n",
    "\n",
    "# Assuming you have already trained your model and saved its weights\n",
    "model_filepath = 'resnet_model_weights.pth'  # Provide the correct filepath\n",
    "predict_external_image(model, model_filepath)\n",
    "\n",
    "# Close the window\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:13:28.279293Z",
     "start_time": "2024-03-11T17:13:28.078704Z"
    }
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[23]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T17:13:30.098944Z",
     "start_time": "2024-03-11T17:13:29.911675Z"
    }
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[51]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting External Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test with external images.\n",
    "\n",
    "I'll use `urllib` for downloading external images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fengage.vic.gov.au%2Fapplication%2Ffiles%2F1415%2F0596%2F9236%2FDSC_0026.JPG&f=1&nofb=1\", \"plastic.jpg\")\n",
    "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fi.ebayimg.com%2Fimages%2Fi%2F291536274730-0-1%2Fs-l1000.jpg&f=1&nofb=1\", \"cardboard.jpg\")    \n",
    "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%3Fid%3DOIP.2F0uH6BguQMctAYEJ-s-1gHaHb%26pid%3DApi&f=1\", \"cans.jpg\") \n",
    "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftinytrashcan.com%2Fwp-content%2Fuploads%2F2018%2F08%2Ftiny-trash-can-bulk-wine-bottle.jpg&f=1&nofb=1\", \"wine-trash.jpg\")\n",
    "urllib.request.urlretrieve(\"http://ourauckland.aucklandcouncil.govt.nz/media/7418/38-94320.jpg\", \"paper-trash.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the model. You can load an external pre-trained model too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the image's name and prints the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_external_image(image_name):\n",
    "    image = Image.open(Path('./' + image_name))\n",
    "\n",
    "    example_image = transformations(image)\n",
    "    plt.imshow(example_image.permute(1, 2, 0))\n",
    "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_external_image(image_name):\n",
    "    image = Image.open(Path('./' + image_name))\n",
    "\n",
    "    example_image = transformations(image)\n",
    "    plt.imshow(example_image.permute(1, 2, 0))\n",
    "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")\n",
    "    \n",
    "predict_external_image('cans.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_external_image('cardboard.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_external_image('plastic.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_external_image('wine-trash.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_external_image('paper-trash.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "Our model is able to classify garbage with **95% accuracy**!\n",
    "\n",
    "It's great to see the model's predictions on the test set. It works pretty good on external images too!\n",
    "\n",
    "You can try experimenting with more images and see the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you liked the kernel, don't forget to show some appreciation :)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 81794,
     "sourceId": 189983,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30461,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
